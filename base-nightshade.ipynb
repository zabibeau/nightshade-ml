{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8740f10",
   "metadata": {},
   "source": [
    "# Nightshade penalty method validation and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f48783b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9581ac28",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'nightshade_env (Python 3.10.12)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/zabibeau/Spring2025/MachineLearning/nightshade-ml/nightshade_env/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Package imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from IPython.display import display\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import clip\n",
    "\n",
    "# Our custom implementations\n",
    "from nightshade import Nightshade\n",
    "from perturbation_methods import fgsm_penalty, pgd_penalty, nightshade_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723ec02",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31edd13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "target_concept = 'cat'\n",
    "epsilon = 0.1\n",
    "test_image_path = 'test_images/dog.jpg'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ed2ccb",
   "metadata": {},
   "source": [
    "## Initialize Nightshade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ff354",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    'fgsm': fgsm_penalty,\n",
    "    'pgd': pgd_penalty,\n",
    "    'nightshade': nightshade_penalty\n",
    "}\n",
    "\n",
    "nightshade_instances = {\n",
    "    name: Nightshade(\n",
    "        target_concept=target_concept,\n",
    "        device=device,\n",
    "        epsilon=epsilon,\n",
    "        method=method,\n",
    "    ) \n",
    "    for name, method in methods.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5342b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_image(path, size=512):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.CenterCrop(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    "    return transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "original_img = load_and_prepare_image(test_image_path)\n",
    "\n",
    "def visualize_results(original, perturbed, method_name):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    orig_img = original.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "    orig_img = (orig_img * 0.5 + 0.5).clip(0, 1)\n",
    "    ax1.imshow(orig_img)\n",
    "    ax1.set_title(\"Original Image\")\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Perturbed image\n",
    "    pert_img = perturbed.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "    pert_img = (pert_img * 0.5 + 0.5).clip(0, 1)\n",
    "    ax2.imshow(pert_img)\n",
    "    ax2.set_title(f\"{method_name} Perturbed\")\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    # Difference (magnified)\n",
    "    diff = np.abs(pert_img - orig_img) * 10  # Amplify differences\n",
    "    ax3.imshow(diff.clip(0, 1))\n",
    "    ax3.set_title(\"Difference (10x)\")\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"## Validation Test 1: Basic Functionality\")\n",
    "\n",
    "test_img = Image.open(test_image_path).convert(\"RGB\")\n",
    "\n",
    "for name, instance in nightshade_instances.items():\n",
    "    print(f\"\\nTesting {name} method...\")\n",
    "    start_time = time.time()\n",
    "    perturbed_img = instance.generate(test_img)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"Completed in {elapsed:.2f} seconds\")\n",
    "    display(perturbed_img)\n",
    "    \n",
    "    # Convert back to tensor for visualization\n",
    "    perturbed_tensor = instance.transform(perturbed_img).unsqueeze(0).to(DEVICE)\n",
    "    visualize_results(original_img, perturbed_tensor, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac5644",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"## Validation Test 2: Latent Space Manipulation\")\n",
    "\n",
    "def compare_latents(original, perturbed, nightshade_instance):\n",
    "    with torch.no_grad():\n",
    "        orig_latent = nightshade_instance.get_latent(original)\n",
    "        pert_latent = nightshade_instance.get_latent(perturbed)\n",
    "    \n",
    "    distance = torch.norm(orig_latent - pert_latent).item()\n",
    "    cosine_sim = torch.nn.functional.cosine_similarity(\n",
    "        orig_latent.flatten(), \n",
    "        pert_latent.flatten(), \n",
    "        dim=0\n",
    "    ).item()\n",
    "    \n",
    "    return distance, cosine_sim\n",
    "\n",
    "results = []\n",
    "for name, instance in nightshade_instances.items():\n",
    "    perturbed_img = instance.generate(test_img)\n",
    "    perturbed_tensor = instance.transform(perturbed_img).unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    dist, sim = compare_latents(original_img, perturbed_tensor, instance)\n",
    "    results.append({\n",
    "        \"Method\": name,\n",
    "        \"Latent Distance\": dist,\n",
    "        \"Cosine Similarity\": sim\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nLatent Space Comparison:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd63292",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"## Validation Test 3: Effectiveness Against Model\")\n",
    "\n",
    "def test_model_misclassification(original, perturbed, target_concept):\n",
    "    # Load CLIP model for evaluation\n",
    "    model, preprocess = clip.load(\"ViT-B/32\", device=DEVICE)\n",
    "    \n",
    "    # Preprocess images\n",
    "    orig_preprocessed = preprocess(original).unsqueeze(0).to(DEVICE)\n",
    "    pert_preprocessed = preprocess(perturbed).unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    # Text prompts\n",
    "    text_inputs = clip.tokenize([\n",
    "        f\"a photo of a {target_concept}\",\n",
    "        \"a photo of an artwork\",\n",
    "        \"a photo of the original content\"\n",
    "    ]).to(DEVICE)\n",
    "    \n",
    "    # Calculate features\n",
    "    with torch.no_grad():\n",
    "        orig_features = model.encode_image(orig_preprocessed)\n",
    "        pert_features = model.encode_image(pert_preprocessed)\n",
    "        text_features = model.encode_text(text_inputs)\n",
    "    \n",
    "    # Calculate similarities\n",
    "    orig_similarities = (orig_features @ text_features.T).softmax(dim=-1)\n",
    "    pert_similarities = (pert_features @ text_features.T).softmax(dim=-1)\n",
    "    \n",
    "    return {\n",
    "        \"Original Confidence\": orig_similarities[0][0].item(),\n",
    "        \"Perturbed Confidence\": pert_similarities[0][0].item(),\n",
    "        \"Confidence Increase\": pert_similarities[0][0].item() - orig_similarities[0][0].item()\n",
    "    }\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = []\n",
    "for name, instance in nightshade_instances.items():\n",
    "    perturbed_img = instance.generate(test_img)\n",
    "    perturbed_tensor = instance.transform(perturbed_img).unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    metrics = test_model_misclassification(\n",
    "        original_img, \n",
    "        perturbed_tensor, \n",
    "        TARGET_CONCEPT\n",
    "    )\n",
    "    metrics[\"Method\"] = name\n",
    "    evaluation_results.append(metrics)\n",
    "\n",
    "evaluation_df = pd.DataFrame(evaluation_results)\n",
    "print(\"\\nMisclassification Effectiveness:\")\n",
    "display(evaluation_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nightshade_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
